{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用pands合并数据集\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('/kaggle/input/datasplit/valid_data1.csv')\n",
    "df2 = pd.read_csv('/kaggle/input/datasplit/valid_data2.csv')\n",
    "df3 = pd.read_csv('/kaggle/input/datasplit/valid_data3.csv')\n",
    "df = pd.concat([df1,df2,df3], axis=0, ignore_index=True)\n",
    "df.to_csv('valid_data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 网址合法性检测,输入url,输出True/False,True为合法网址、False为不合法网址\n",
    "import tldextract\n",
    "def is_valid_url(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    if not ext.domain or not ext.suffix:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 网址有效性检测，输入url,输出True/False,True为有效网址、False为失效网址\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def parsed_url(url):\n",
    "    try:\n",
    "        if not url.startswith(\"http\"):\n",
    "            url = \"http://\" + url\n",
    "        response = requests.get(url, timeout=1.5)\n",
    "        if response.status_code == 404 or response.status_code == 403:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##提取文本信息，对于带有文本信息的数据，输入context，对于无文本信息的数据输入url，返回text\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import jieba\n",
    "import pygtrans\n",
    "from pygtrans import Translate\n",
    "from collections import Counter\n",
    "import re\n",
    "## 提取文本信息（带有文本信息的数据）\n",
    "def get_context(context):\n",
    "    client = Translate()\n",
    "    seg_list = jieba.cut(context)\n",
    "    word_counts = Counter(seg_list)\n",
    "    if len(word_counts) == 0:\n",
    "        output = \",\"\n",
    "    else:\n",
    "        top5 = word_counts.most_common(100)\n",
    "        top5 = [word[0]\n",
    "                for word in top5[:100] if len(word[0]) > 1]  # 过滤掉非词语的关键词\n",
    "        output = \",\".join(top5[:5])\n",
    "        output = client.translate(output, 'en').translatedText\n",
    "        pattern = re.compile('[^0-9a-zA-Z,/:\\-]')\n",
    "    return pattern.sub('', output)\n",
    "\n",
    "## 未带有文本信息的数据\n",
    "def get_url_context(url):\n",
    "    try:\n",
    "        if not url.startswith(\"http\"):\n",
    "            url = \"http://\" + url\n",
    "        response = requests.get(url, timeout=2)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        output = get_context(text)\n",
    "        return output\n",
    "    except:\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## smote 数据增强\n",
    "from imblearn.over_sampling import SMOTE\n",
    "##这里的输入X，Y是处理完的编码数据\n",
    "def data_smote(X,Y):\n",
    "    smote = SMOTE(sampling_strategy='auto', k_neighbors=3)\n",
    "    X, Y = smote.fit_resample(X, Y)\n",
    "    return X,Y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
